import numpy as np
import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

params = pickle.load(open('param_dict.pkl', 'rb'))

def kl_loss(mean, variance):
    """
    It computes Kullback-Leibler divergence loss for the genrator
    mean: mean of the conditioning distribution.
    variance: variance of the conditioning distribution.
    """
    kld_value = mean.pow(2).add_(variance.exp()).mul_(-1).add_(1).add_(variance)
    kld = torch.mean(kld_value).mul_(-0.5)
    return kld



def discriminator_loss(discriminator, fake_images, real_images, fake_labels, real_labels, con_aug, stage):

    """
    This function computes the loss for updating the discriminator.
    discriminator: discriminator object
    fake_images: fake images generated by the generator.  It should be detached from the computation graph
                 so that gradients don't flow through generator.
    real_image: real_images from the dataset.
    fake_labels: labels for generated image.
    real_labels: labels for real image.
    con_aug: the augmentation vector used for decision making.
    stage: Specifies which stage the loss is to be computed
    """
    discriminator.train()
    criterion = nn.BCELoss()
    fake = fake_images.detach()
    condition = con_aug.detach()
    batch_size = real_images.size(0)
    """
    ********************************************************************************
    The next two lines should be removed if we don't have a very powerful GPU.
    I cannot train the 256 x 256 image in stage 2 in my GPU(Tesla K80). So modified stage 2
    so that all processing are done for 64 x 64 and output is also 64 x 64 image.
    *********************************************************************************
    """
    if (stage==2):
        real_images = F.interpolate(real_images, scale_factor = 4)
    real_dis_fea = discriminator(real_images)
    fake_dis_fea = discriminator(fake)

    """
    Here we use three types of error and add them.
    real_error: error between real images and real labels.
    wrong_error: error between real images and wrong labels.
    fake_error: error between fake images and fake labels.
    """
    real_logits = discriminator.conditioned_result(real_dis_fea, condition)
    real_error = criterion(real_logits, real_labels)

    wrong_logits = discriminator.conditioned_result(real_dis_fea[:(batch_size-1)], condition[1:])
    wrong_error = criterion(wrong_logits, fake_labels[1:])

    fake_logits = discriminator.conditioned_result(fake_dis_fea, condition)
    fake_error = criterion(fake_logits, fake_labels)

    if discriminator.unconditioned_result is not None:
        """
        In case of stage 2 generator in addition to above errors we also
        use another error calculated from scores computed using the image features
        only without using the text features.
        """
        real_logits1 = discriminator.unconditioned_result(real_dis_fea)
        uncond_real_error = criterion(real_logits1, real_labels)

        fake_logits1 = discriminator.unconditioned_result(fake_dis_fea)
        uncond_fake_error = criterion(fake_logits1, fake_labels)

        error = (real_error + uncond_real_error)/2.0 + (wrong_error+fake_error+uncond_fake_error)/3.0
        real_error = (real_error + uncond_real_error)/2.0
        fake_error = (fake_error + uncond_fake_error)/2.0

    else:
        error = real_error + (wrong_error * fake_error) * 0.5

    return error, real_error.item(), fake_error.item(), wrong_error.item()




def generator_loss(discriminator, fake_images, real_labels, con_aug):

    """
    This function computes the loss for updating the generator.
    discriminator: discriminator object.
    fake_images: fake images generated by the generator.
    real_labels: They are given real labels as the update as to be done to make them look like images
                 from original distribution.
    con_aug: the augmentation vector used for score calculation.
    """

    discriminator.train()
    criterion = nn.BCELoss()
    condition = con_aug.detach()
    fake_img_fea = discriminator(fake_images)
    fake_logits = discriminator.conditioned_result(fake_img_fea, condition)
    fake_error = criterion(fake_logits, real_labels)

    if discriminator.unconditioned_result is not None:
        """
        If it is a stage 2 discriminator then an additional error due to the
        score calculated from image features alone is added to the above error
        for loss calculation.
        """
        fake_logits1 = discriminator.unconditioned_result(fake_img_fea)
        uncond_fake_error = criterion(fake_logits1, real_labels)
        fake_error += uncond_fake_error
    return fake_error
